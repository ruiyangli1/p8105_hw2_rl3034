P8105 Homework 2
================
Ruiyang Li

This is my solution to HW2.

``` r
library(readxl)
library(tidyverse)
```

    ## -- Attaching packages ------------------------------------------- tidyverse 1.3.0 --

    ## v ggplot2 3.3.2     v purrr   0.3.4
    ## v tibble  3.0.3     v dplyr   1.0.0
    ## v tidyr   1.1.0     v stringr 1.4.0
    ## v readr   1.3.1     v forcats 0.5.0

    ## -- Conflicts ---------------------------------------------- tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

## Problem 1

Read and clean the Mr. Trash Wheel sheet:

``` r
mr_trash_wheel = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
    sheet = "Mr. Trash Wheel", 
    range = cell_cols("A:N"),
    skip = 1) %>% 
  janitor::clean_names() %>%
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  ) 
```

Read and clean precipitation data for 2017 and 2018:

``` r
precip_2017 = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    range = "A2:B14") %>% 
  janitor::clean_names() %>%   
  mutate(year = "2017") %>% 
  relocate(year)
  
precip_2018 = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
    sheet = "2018 Precipitation",
    range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = "2018") %>% 
  relocate(year)
```

Combine precipitation datasets:

``` r
precip = 
  bind_rows(precip_2017, precip_2018) %>% 
  mutate(month = month.name[month])
```

About these data:

For the Mr. Trash Wheel dataset, there are 14 variables with 344
observations. Variables include: dumpster, month, year, date,
weight\_tons, volume\_cubic\_yards, plastic\_bottles, polystyrene,
cigarette\_butts, glass\_bottles, grocery\_bags, chip\_bags,
sports\_balls, homes\_powered. Data on 344 dumpsters were collected from
2014 to 2019. The total weight of trash is 1122.45 tons. These trash was
incinerated to provide electricity for 15076 Maryland homes. The median
number of sports balls in a dumpster is 8.

For the combined precipitation dataset, there are 3 variables with 24
observations. Variables include: year, month, total. For example, the
total precipitation in 2018 was 70.33 (in).

## Problem 2

Read and clean the nyc transit data:

``` r
nyc_transit = 
  read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

About this dataset:

The raw NYC transit dataset contains 32 variables. During the data
cleaning process, I first cleaned the variables’ names by making them
all snake case, then I selected the 19 variables of interest: line,
station\_name, station\_latitude, station\_longitude, route1, route2,
route3, route4, route5, route6, route7, route8, route9, route10,
route11, entry, vending, entrance\_type, ada, and finally I converted
the variable `entry` from character (`YES` vs `NO`) to logical (`TRUE`
vs `FALSE`). The resulting dataset has 19 variables with dimension 1868
x 19. Data in this resulting dataset are not tidy. For example, the
current 11 route variables can be reduced into one route variable
indicating different route numbers. Also, duplicated rows were created
from the process of selecting partial columns.

More about the dataset:

``` r
nyc_transit_distinct = 
  nyc_transit %>% 
  distinct(line, station_name, .keep_all = TRUE)
```

  - There are 465 distinct stations.
  - There are 84 stations that are ADA compliant.
  - 37.7% of station entrances / exits without vending allow entrance.

Reformat data so that route number and route name are distinct
variables:

``` r
nyc_transit_reformat = 
  nyc_transit_distinct %>% 
  mutate_at(vars(route8:route11), as.character) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    names_prefix = "route",
    values_to = "route_number")

nyc_transit_a = 
  nyc_transit_reformat %>% 
  filter(route_number == "A") %>% 
  distinct(line, station_name, .keep_all = TRUE)
```

  - There are 60 distinct stations serve the A train.
  - Of the stations that serve the A train, 17 are ADA compliant.

## Problem 3

Clean pols-month.csv:

``` r
pols = 
  read_csv("./data/pols-month.csv") %>% 
  separate(mon, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(
    month = month.name[as.numeric(month)], 
    president = ifelse(prez_dem == 1, "dem", ifelse(prez_gop == 1, "gop", "other"))
  ) %>% 
  select(-prez_dem, -prez_gop, -day)
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

Clean snp.csv:

``` r
snp = 
  read_csv("./data/snp.csv") %>% 
  separate(date, into = c("month", "day", "year"), sep = "/") %>% 
  mutate(month = month.name[as.numeric(month)]) %>% 
  select(-day) %>% 
  relocate(year)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

Tidy unemployment.csv:

``` r
unemployment = 
  read_csv("./data/unemployment.csv") %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month", 
    values_to = "unemployment"
  ) %>% 
  janitor::clean_names() %>% 
  mutate(
    month = month.name[match(month, month.abb)],
    year = as.character(year)
  )
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

Merge snp into pols, and merge unemployment into the result:

``` r
merge_df = left_join(pols, snp, by = c("year", "month"))

merge_df = left_join(merge_df, unemployment, by = c("year", "month"))
```

About these datasets:

The file “pols” contains 822 observations of 9 variables (year, month,
gov\_gop, sen\_gop, rep\_gop, gov\_dem, sen\_dem, rep\_dem, president)
related to the number of national politicians who are democratic or
republican at any given time.

The file “snp” contains 787 observations of 3 variables (year, month,
close) related to Standard & Poor’s stock market index (S\&P), often
used as a representative measure of stock market as a whole.

The file “unemployment” contains 816 observations of 3 variables (year,
month, unemployment).

The merged dataset has dimension 822x11. Data was collected from year
1947 to 2015. Key variables in this dataset includes:

  - `president`: indicator of whether the president was republican or
    democratic or other at the associated time
  - `close`: the closing values of the S\&P stock index at the
    associated time
  - `unemployment`: percentage of unemployment at the associated time
